{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "\n",
      "parameters:\n",
      "{'ccp_alpha': None, 'class_weight': None, 'criterion': None, 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': None, 'min_impurity_split': None, 'min_samples_leaf': None, 'min_samples_split': None, 'min_weight_fraction_leaf': None, 'presort': None, 'random_state': None, 'splitter': None}\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 9, 'splitter': 'random'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.070 (+/-0.023) for {'criterion': 'gini', 'max_depth': 1, 'splitter': 'best'}\n",
      "0.056 (+/-0.038) for {'criterion': 'gini', 'max_depth': 1, 'splitter': 'random'}\n",
      "0.232 (+/-0.070) for {'criterion': 'gini', 'max_depth': 2, 'splitter': 'best'}\n",
      "0.177 (+/-0.024) for {'criterion': 'gini', 'max_depth': 2, 'splitter': 'random'}\n",
      "0.425 (+/-0.141) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.394 (+/-0.132) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.595 (+/-0.111) for {'criterion': 'gini', 'max_depth': 4, 'splitter': 'best'}\n",
      "0.599 (+/-0.108) for {'criterion': 'gini', 'max_depth': 4, 'splitter': 'random'}\n",
      "0.672 (+/-0.121) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.714 (+/-0.067) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.748 (+/-0.057) for {'criterion': 'gini', 'max_depth': 6, 'splitter': 'best'}\n",
      "0.741 (+/-0.058) for {'criterion': 'gini', 'max_depth': 6, 'splitter': 'random'}\n",
      "0.784 (+/-0.030) for {'criterion': 'gini', 'max_depth': 7, 'splitter': 'best'}\n",
      "0.774 (+/-0.058) for {'criterion': 'gini', 'max_depth': 7, 'splitter': 'random'}\n",
      "0.788 (+/-0.045) for {'criterion': 'gini', 'max_depth': 8, 'splitter': 'best'}\n",
      "0.794 (+/-0.098) for {'criterion': 'gini', 'max_depth': 8, 'splitter': 'random'}\n",
      "0.804 (+/-0.059) for {'criterion': 'gini', 'max_depth': 9, 'splitter': 'best'}\n",
      "0.803 (+/-0.047) for {'criterion': 'gini', 'max_depth': 9, 'splitter': 'random'}\n",
      "0.799 (+/-0.032) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.813 (+/-0.045) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.046 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'best'}\n",
      "0.042 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'random'}\n",
      "0.186 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 2, 'splitter': 'best'}\n",
      "0.168 (+/-0.050) for {'criterion': 'entropy', 'max_depth': 2, 'splitter': 'random'}\n",
      "0.512 (+/-0.105) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.420 (+/-0.043) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.665 (+/-0.037) for {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'best'}\n",
      "0.698 (+/-0.058) for {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'random'}\n",
      "0.741 (+/-0.047) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.745 (+/-0.029) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.796 (+/-0.041) for {'criterion': 'entropy', 'max_depth': 6, 'splitter': 'best'}\n",
      "0.794 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 6, 'splitter': 'random'}\n",
      "0.812 (+/-0.049) for {'criterion': 'entropy', 'max_depth': 7, 'splitter': 'best'}\n",
      "0.809 (+/-0.057) for {'criterion': 'entropy', 'max_depth': 7, 'splitter': 'random'}\n",
      "0.822 (+/-0.036) for {'criterion': 'entropy', 'max_depth': 8, 'splitter': 'best'}\n",
      "0.798 (+/-0.040) for {'criterion': 'entropy', 'max_depth': 8, 'splitter': 'random'}\n",
      "0.811 (+/-0.037) for {'criterion': 'entropy', 'max_depth': 9, 'splitter': 'best'}\n",
      "0.826 (+/-0.086) for {'criterion': 'entropy', 'max_depth': 9, 'splitter': 'random'}\n",
      "0.818 (+/-0.041) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.817 (+/-0.069) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        89\n",
      "           1       0.70      0.77      0.73        90\n",
      "           2       0.83      0.76      0.80        92\n",
      "           3       0.67      0.77      0.72        93\n",
      "           4       0.76      0.88      0.82        76\n",
      "           5       0.87      0.71      0.78       108\n",
      "           6       0.93      0.92      0.93        89\n",
      "           7       0.78      0.86      0.82        78\n",
      "           8       0.69      0.59      0.64        92\n",
      "           9       0.77      0.77      0.77        92\n",
      "\n",
      "    accuracy                           0.80       899\n",
      "   macro avg       0.80      0.80      0.80       899\n",
      "weighted avg       0.80      0.80      0.79       899\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'splitter': 'random'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.192 (+/-0.008) for {'criterion': 'gini', 'max_depth': 1, 'splitter': 'best'}\n",
      "0.187 (+/-0.028) for {'criterion': 'gini', 'max_depth': 1, 'splitter': 'random'}\n",
      "0.307 (+/-0.053) for {'criterion': 'gini', 'max_depth': 2, 'splitter': 'best'}\n",
      "0.330 (+/-0.031) for {'criterion': 'gini', 'max_depth': 2, 'splitter': 'random'}\n",
      "0.428 (+/-0.114) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.484 (+/-0.058) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.574 (+/-0.099) for {'criterion': 'gini', 'max_depth': 4, 'splitter': 'best'}\n",
      "0.632 (+/-0.062) for {'criterion': 'gini', 'max_depth': 4, 'splitter': 'random'}\n",
      "0.623 (+/-0.096) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.671 (+/-0.084) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.723 (+/-0.043) for {'criterion': 'gini', 'max_depth': 6, 'splitter': 'best'}\n",
      "0.729 (+/-0.070) for {'criterion': 'gini', 'max_depth': 6, 'splitter': 'random'}\n",
      "0.759 (+/-0.033) for {'criterion': 'gini', 'max_depth': 7, 'splitter': 'best'}\n",
      "0.757 (+/-0.064) for {'criterion': 'gini', 'max_depth': 7, 'splitter': 'random'}\n",
      "0.773 (+/-0.037) for {'criterion': 'gini', 'max_depth': 8, 'splitter': 'best'}\n",
      "0.755 (+/-0.034) for {'criterion': 'gini', 'max_depth': 8, 'splitter': 'random'}\n",
      "0.797 (+/-0.050) for {'criterion': 'gini', 'max_depth': 9, 'splitter': 'best'}\n",
      "0.791 (+/-0.072) for {'criterion': 'gini', 'max_depth': 9, 'splitter': 'random'}\n",
      "0.782 (+/-0.058) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.806 (+/-0.031) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.191 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'best'}\n",
      "0.192 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'random'}\n",
      "0.352 (+/-0.039) for {'criterion': 'entropy', 'max_depth': 2, 'splitter': 'best'}\n",
      "0.346 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 2, 'splitter': 'random'}\n",
      "0.553 (+/-0.031) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.531 (+/-0.074) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.662 (+/-0.041) for {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'best'}\n",
      "0.608 (+/-0.115) for {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'random'}\n",
      "0.730 (+/-0.048) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.709 (+/-0.053) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.780 (+/-0.030) for {'criterion': 'entropy', 'max_depth': 6, 'splitter': 'best'}\n",
      "0.767 (+/-0.082) for {'criterion': 'entropy', 'max_depth': 6, 'splitter': 'random'}\n",
      "0.806 (+/-0.054) for {'criterion': 'entropy', 'max_depth': 7, 'splitter': 'best'}\n",
      "0.786 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 7, 'splitter': 'random'}\n",
      "0.812 (+/-0.051) for {'criterion': 'entropy', 'max_depth': 8, 'splitter': 'best'}\n",
      "0.823 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 8, 'splitter': 'random'}\n",
      "0.819 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 9, 'splitter': 'best'}\n",
      "0.810 (+/-0.018) for {'criterion': 'entropy', 'max_depth': 9, 'splitter': 'random'}\n",
      "0.812 (+/-0.061) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.805 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        89\n",
      "           1       0.83      0.82      0.83        90\n",
      "           2       0.73      0.73      0.73        92\n",
      "           3       0.78      0.83      0.80        93\n",
      "           4       0.89      0.86      0.87        76\n",
      "           5       0.92      0.79      0.85       108\n",
      "           6       0.82      0.94      0.88        89\n",
      "           7       0.82      0.82      0.82        78\n",
      "           8       0.68      0.75      0.71        92\n",
      "           9       0.85      0.74      0.79        92\n",
      "\n",
      "    accuracy                           0.82       899\n",
      "   macro avg       0.83      0.83      0.83       899\n",
      "weighted avg       0.83      0.82      0.82       899\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'splitter': 'random'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.094 (+/-0.021) for {'criterion': 'gini', 'max_depth': 1, 'splitter': 'best'}\n",
      "0.074 (+/-0.014) for {'criterion': 'gini', 'max_depth': 1, 'splitter': 'random'}\n",
      "0.224 (+/-0.031) for {'criterion': 'gini', 'max_depth': 2, 'splitter': 'best'}\n",
      "0.218 (+/-0.012) for {'criterion': 'gini', 'max_depth': 2, 'splitter': 'random'}\n",
      "0.360 (+/-0.125) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.395 (+/-0.106) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.535 (+/-0.116) for {'criterion': 'gini', 'max_depth': 4, 'splitter': 'best'}\n",
      "0.566 (+/-0.153) for {'criterion': 'gini', 'max_depth': 4, 'splitter': 'random'}\n",
      "0.614 (+/-0.125) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.677 (+/-0.101) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.727 (+/-0.042) for {'criterion': 'gini', 'max_depth': 6, 'splitter': 'best'}\n",
      "0.758 (+/-0.105) for {'criterion': 'gini', 'max_depth': 6, 'splitter': 'random'}\n",
      "0.764 (+/-0.034) for {'criterion': 'gini', 'max_depth': 7, 'splitter': 'best'}\n",
      "0.770 (+/-0.060) for {'criterion': 'gini', 'max_depth': 7, 'splitter': 'random'}\n",
      "0.782 (+/-0.045) for {'criterion': 'gini', 'max_depth': 8, 'splitter': 'best'}\n",
      "0.787 (+/-0.054) for {'criterion': 'gini', 'max_depth': 8, 'splitter': 'random'}\n",
      "0.789 (+/-0.024) for {'criterion': 'gini', 'max_depth': 9, 'splitter': 'best'}\n",
      "0.805 (+/-0.093) for {'criterion': 'gini', 'max_depth': 9, 'splitter': 'random'}\n",
      "0.786 (+/-0.060) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.791 (+/-0.028) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.073 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'best'}\n",
      "0.069 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'random'}\n",
      "0.227 (+/-0.033) for {'criterion': 'entropy', 'max_depth': 2, 'splitter': 'best'}\n",
      "0.208 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 2, 'splitter': 'random'}\n",
      "0.494 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.446 (+/-0.064) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.651 (+/-0.047) for {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'best'}\n",
      "0.643 (+/-0.115) for {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'random'}\n",
      "0.730 (+/-0.058) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.724 (+/-0.048) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.782 (+/-0.048) for {'criterion': 'entropy', 'max_depth': 6, 'splitter': 'best'}\n",
      "0.731 (+/-0.114) for {'criterion': 'entropy', 'max_depth': 6, 'splitter': 'random'}\n",
      "0.801 (+/-0.044) for {'criterion': 'entropy', 'max_depth': 7, 'splitter': 'best'}\n",
      "0.816 (+/-0.056) for {'criterion': 'entropy', 'max_depth': 7, 'splitter': 'random'}\n",
      "0.813 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 8, 'splitter': 'best'}\n",
      "0.819 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 8, 'splitter': 'random'}\n",
      "0.788 (+/-0.067) for {'criterion': 'entropy', 'max_depth': 9, 'splitter': 'best'}\n",
      "0.816 (+/-0.080) for {'criterion': 'entropy', 'max_depth': 9, 'splitter': 'random'}\n",
      "0.798 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.803 (+/-0.060) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94        89\n",
      "           1       0.85      0.84      0.85        90\n",
      "           2       0.87      0.83      0.85        92\n",
      "           3       0.75      0.91      0.82        93\n",
      "           4       0.89      0.89      0.89        76\n",
      "           5       0.91      0.75      0.82       108\n",
      "           6       0.86      0.84      0.85        89\n",
      "           7       0.79      0.92      0.85        78\n",
      "           8       0.70      0.71      0.70        92\n",
      "           9       0.85      0.80      0.83        92\n",
      "\n",
      "    accuracy                           0.84       899\n",
      "   macro avg       0.84      0.84      0.84       899\n",
      "weighted avg       0.84      0.84      0.84       899\n",
      "\n",
      "\n",
      "Time Consumed: 3.06325626373291\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator as est\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {'splitter':['best', 'random'],'max_depth':[1,2,3,4,5,6,7,8,9,10],\n",
    "                    'criterion':['gini', 'entropy']}\n",
    "\n",
    "scores = ['precision', 'recall','f1']\n",
    "\n",
    "print('\\n' + 'parameters:' + \"\\n\" + str(est.get_params(DecisionTreeClassifier)) + '\\n')\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        DecisionTreeClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "print(\"Time Consumed: \" + str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "\n",
      "parameters:\n",
      "{'ccp_alpha': None, 'class_weight': None, 'criterion': None, 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': None, 'min_impurity_split': None, 'min_samples_leaf': None, 'min_samples_split': None, 'min_weight_fraction_leaf': None, 'presort': None, 'random_state': None, 'splitter': None}\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'splitter': 'random', 'max_depth': 8, 'criterion': 'entropy'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.741 (+/-0.042) for {'splitter': 'best', 'max_depth': 5, 'criterion': 'entropy'}\n",
      "0.793 (+/-0.079) for {'splitter': 'random', 'max_depth': 10, 'criterion': 'gini'}\n",
      "0.425 (+/-0.141) for {'splitter': 'best', 'max_depth': 3, 'criterion': 'gini'}\n",
      "0.798 (+/-0.033) for {'splitter': 'best', 'max_depth': 9, 'criterion': 'gini'}\n",
      "0.776 (+/-0.069) for {'splitter': 'random', 'max_depth': 7, 'criterion': 'gini'}\n",
      "0.186 (+/-0.034) for {'splitter': 'best', 'max_depth': 2, 'criterion': 'entropy'}\n",
      "0.810 (+/-0.048) for {'splitter': 'random', 'max_depth': 8, 'criterion': 'entropy'}\n",
      "0.797 (+/-0.029) for {'splitter': 'best', 'max_depth': 10, 'criterion': 'entropy'}\n",
      "0.661 (+/-0.112) for {'splitter': 'best', 'max_depth': 5, 'criterion': 'gini'}\n",
      "0.776 (+/-0.046) for {'splitter': 'best', 'max_depth': 7, 'criterion': 'gini'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        89\n",
      "           1       0.72      0.81      0.76        90\n",
      "           2       0.89      0.80      0.85        92\n",
      "           3       0.86      0.86      0.86        93\n",
      "           4       0.80      0.87      0.83        76\n",
      "           5       0.89      0.79      0.84       108\n",
      "           6       0.92      0.90      0.91        89\n",
      "           7       0.87      0.87      0.87        78\n",
      "           8       0.83      0.79      0.81        92\n",
      "           9       0.72      0.76      0.74        92\n",
      "\n",
      "    accuracy                           0.84       899\n",
      "   macro avg       0.84      0.84      0.84       899\n",
      "weighted avg       0.84      0.84      0.84       899\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'splitter': 'best', 'max_depth': 7, 'criterion': 'entropy'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.427 (+/-0.114) for {'splitter': 'best', 'max_depth': 3, 'criterion': 'gini'}\n",
      "0.742 (+/-0.097) for {'splitter': 'random', 'max_depth': 5, 'criterion': 'entropy'}\n",
      "0.744 (+/-0.068) for {'splitter': 'random', 'max_depth': 6, 'criterion': 'entropy'}\n",
      "0.782 (+/-0.045) for {'splitter': 'best', 'max_depth': 8, 'criterion': 'gini'}\n",
      "0.570 (+/-0.102) for {'splitter': 'best', 'max_depth': 4, 'criterion': 'gini'}\n",
      "0.799 (+/-0.019) for {'splitter': 'best', 'max_depth': 7, 'criterion': 'entropy'}\n",
      "0.795 (+/-0.024) for {'splitter': 'random', 'max_depth': 8, 'criterion': 'entropy'}\n",
      "0.717 (+/-0.048) for {'splitter': 'random', 'max_depth': 5, 'criterion': 'gini'}\n",
      "0.758 (+/-0.033) for {'splitter': 'best', 'max_depth': 7, 'criterion': 'gini'}\n",
      "0.761 (+/-0.081) for {'splitter': 'random', 'max_depth': 7, 'criterion': 'gini'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        89\n",
      "           1       0.67      0.84      0.75        90\n",
      "           2       0.97      0.73      0.83        92\n",
      "           3       0.81      0.74      0.78        93\n",
      "           4       0.80      0.83      0.81        76\n",
      "           5       0.80      0.84      0.82       108\n",
      "           6       0.94      0.89      0.91        89\n",
      "           7       0.79      0.87      0.83        78\n",
      "           8       0.63      0.64      0.64        92\n",
      "           9       0.93      0.76      0.84        92\n",
      "\n",
      "    accuracy                           0.81       899\n",
      "   macro avg       0.82      0.81      0.81       899\n",
      "weighted avg       0.82      0.81      0.81       899\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'splitter': 'random', 'max_depth': 7, 'criterion': 'entropy'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.767 (+/-0.046) for {'splitter': 'random', 'max_depth': 8, 'criterion': 'gini'}\n",
      "0.731 (+/-0.053) for {'splitter': 'best', 'max_depth': 5, 'criterion': 'entropy'}\n",
      "0.760 (+/-0.037) for {'splitter': 'best', 'max_depth': 7, 'criterion': 'gini'}\n",
      "0.445 (+/-0.045) for {'splitter': 'random', 'max_depth': 3, 'criterion': 'entropy'}\n",
      "0.649 (+/-0.044) for {'splitter': 'best', 'max_depth': 4, 'criterion': 'entropy'}\n",
      "0.217 (+/-0.048) for {'splitter': 'random', 'max_depth': 2, 'criterion': 'gini'}\n",
      "0.792 (+/-0.017) for {'splitter': 'best', 'max_depth': 9, 'criterion': 'entropy'}\n",
      "0.641 (+/-0.052) for {'splitter': 'random', 'max_depth': 4, 'criterion': 'entropy'}\n",
      "0.725 (+/-0.047) for {'splitter': 'best', 'max_depth': 6, 'criterion': 'gini'}\n",
      "0.829 (+/-0.061) for {'splitter': 'random', 'max_depth': 7, 'criterion': 'entropy'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89        89\n",
      "           1       0.63      0.70      0.66        90\n",
      "           2       0.72      0.71      0.71        92\n",
      "           3       0.73      0.89      0.80        93\n",
      "           4       0.86      0.78      0.81        76\n",
      "           5       0.88      0.62      0.73       108\n",
      "           6       0.81      0.92      0.86        89\n",
      "           7       0.84      0.90      0.87        78\n",
      "           8       0.82      0.55      0.66        92\n",
      "           9       0.69      0.72      0.71        92\n",
      "\n",
      "    accuracy                           0.77       899\n",
      "   macro avg       0.78      0.78      0.77       899\n",
      "weighted avg       0.78      0.77      0.77       899\n",
      "\n",
      "\n",
      "Time Consumed: 0.9388930797576904\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {'splitter':['best', 'random'],'max_depth':[1,2,3,4,5,6,7,8,9,10],\n",
    "                    'criterion':['gini', 'entropy']}\n",
    "\n",
    "scores = ['precision', 'recall','f1']\n",
    "\n",
    "print('\\n' + 'parameters:' + \"\\n\" + str(est.get_params(DecisionTreeClassifier)) + '\\n')\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = RandomizedSearchCV(\n",
    "        DecisionTreeClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "print(\"Time Consumed: \" + str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Grid Search time consumed: 3.06325626373291\n",
    "Randomized Search time consumed: 0.9388930797576904\n",
    "\n",
    "grid search essentially brute forces its way through all possible combinations of hyperparameters \n",
    "and saves the metrics for the combination with the best performance.\n",
    "\n",
    "A randomized search provides an alternative to the exhaustive grid search method. \n",
    "As the name suggests, it randomly selects combinations of hyperparameters and tests them to find the \n",
    "optimal hyperparameter values out of the randomly selected group. \n",
    "This method is typically faster than a grid search since it doesnâ€™t test the full range of possibilities.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
